import os
import re
import json
import logging
import subprocess
from typing import List, Dict, Any, Optional
from datetime import datetime
from .base import BaseWorker
from src.models.vulnerability import Vulnerability, VulnerabilityType

logger = logging.getLogger(__name__)

class ExploitDBWorker(BaseWorker):
    """Worker for fetching exploits from ExploitDB repository."""
    
    def __init__(self, config: Dict[str, Any]):
        """Initialize the ExploitDB worker."""
        super().__init__(config)
        self.repo_dir = os.path.join(self.cache_dir, "exploitdb")
        self.cve_pattern = re.compile(r'CVE-\d{4}-\d{4,7}', re.IGNORECASE)
        self._repo_ready = False
        
        # Ensure cache directory exists
        os.makedirs(self.cache_dir, exist_ok=True)
        os.makedirs(self.repo_dir, exist_ok=True)
    
    @property
    def name(self) -> str:
        return "exploitdb"
    
    def fetch_vulnerabilities(self) -> List[Dict[str, Any]]:
        """Fetch all ExploitDB exploits with real-time saving (full data dump - no checkpoints)."""
        try:
            logger.info(f"[{self.name}] Starting ExploitDB collection with real-time saving")
            logger.info(f"[{self.name}] Processing full data dump - no checkpoints used")
            
            # Setup/update repository
            self._setup_repository()
            
            # Process all exploits with real-time saving
            processed_count = self._process_all_exploits()
            
            logger.info(f"[{self.name}] Processing completed: {processed_count} exploits processed")
            return []  # Return empty list as vulnerabilities are saved real-time
            
        except Exception as e:
            logger.error(f"Error in ExploitDB collection: {e}")
            raise
    
    def _setup_repository(self):
        """Setup or update the ExploitDB repository."""
        try:
            if not os.path.exists(self.repo_dir):
                logger.info(f"[{self.name}] Cloning ExploitDB repository...")
                subprocess.run(
                    ["git", "clone", "https://gitlab.com/exploit-database/exploitdb.git", self.repo_dir],
                    check=True,
                    capture_output=True,
                    text=True
                )
                logger.info(f"[{self.name}] Repository cloned successfully")
            else:
                logger.info(f"[{self.name}] Updating ExploitDB repository...")
                subprocess.run(
                    ["git", "-C", self.repo_dir, "pull"],
                    check=True,
                    capture_output=True,
                    text=True
                )
                logger.info(f"[{self.name}] Repository updated successfully")
            
            self._repo_ready = True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to setup repository: {e.stderr}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error during repository setup: {e}")
            raise
    
    def _process_all_exploits(self) -> int:
        """Process all exploits from ExploitDB with real-time saving."""
        if not self._repo_ready:
            logger.error("Repository not ready for processing")
            return 0
        
        processed_count = 0
        
        try:
            # Define directories to search for exploits
            exploit_dirs = [
                "exploits", "shellcodes", "webapps", "dos", "remote", "local", "papers"
            ]
            
            for dir_name in exploit_dirs:
                dir_path = os.path.join(self.repo_dir, dir_name)
                if not os.path.exists(dir_path):
                    logger.info(f"[{self.name}] Directory {dir_name} not found, skipping")
                    continue
                
                logger.info(f"[{self.name}] Processing directory: {dir_name}")
                dir_processed = 0
                
                # Get all files in directory
                for root, dirs, files in os.walk(dir_path):
                    for file_name in files:
                        file_path = os.path.join(root, file_name)
                        
                        # Skip non-text files and directories
                        if not os.path.isfile(file_path):
                            continue
                        
                        # Skip binary files, images, etc.
                        if any(file_path.lower().endswith(ext) for ext in ['.png', '.jpg', '.gif', '.pdf', '.zip', '.tar', '.gz']):
                            continue
                        
                        try:
                            # Read file content to search for CVEs
                            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                content = f.read()
                            
                            # Skip empty files
                            if not content.strip():
                                continue
                            
                            # Find CVEs in content
                            cve_matches = self.cve_pattern.findall(content)
                            if not cve_matches:
                                continue
                            
                            # Process each unique CVE found in this file
                            unique_cves = list(set(cve_id.upper() for cve_id in cve_matches))
                            
                            for cve_id in unique_cves:
                                # Create unique URL for this exploit file + CVE combination
                                relative_path = os.path.relpath(file_path, self.repo_dir)
                                exploit_url = f"https://gitlab.com/exploit-database/exploitdb/-/blob/main/{relative_path}#{cve_id}"
                                
                                # Check if already processed using MD5 ID
                                vuln_md5_id = Vulnerability.create_id(exploit_url)
                                if self.is_item_processed(vuln_md5_id):
                                    continue
                                
                                # Process exploit into standardized format
                                processed_exploit = self._process_exploit(
                                    file_path, relative_path, cve_id, content, dir_name
                                )
                                
                                if processed_exploit:
                                    # Save immediately in real-time
                                    self.save_vulnerability_realtime(processed_exploit)
                                    dir_processed += 1
                                    processed_count += 1
                                    
                        except Exception as e:
                            logger.error(f"Error processing file {file_path}: {e}")
                            continue
                
                logger.info(f"[{self.name}] Directory {dir_name}: {dir_processed} exploits processed")
            
            return processed_count
            
        except Exception as e:
            logger.error(f"Error processing exploits: {e}")
            raise
    
    def _process_exploit(self, file_path: str, relative_path: str, cve_id: str, content: str, category: str) -> Optional[Dict[str, Any]]:
        """Process a single exploit into standardized format."""
        try:
            # Create unique URL for this exploit
            exploit_url = f"https://gitlab.com/exploit-database/exploitdb/-/blob/main/{relative_path}#{cve_id}"
            
            # Extract basic information
            file_name = os.path.basename(file_path)
            title = f"ExploitDB: {file_name} [{cve_id}]"
            
            # Extract description from content (first few lines or comments)
            description_lines = []
            for line in content.split('\n')[:20]:  # First 20 lines
                line = line.strip()
                if line.startswith('#') or line.startswith('//') or line.startswith('/*'):
                    # Remove comment markers and add to description
                    clean_line = line.lstrip('#/*/ ').strip()
                    if clean_line and len(clean_line) > 10:  # Skip very short lines
                        description_lines.append(clean_line)
                elif line and not line.startswith('<') and len(line) > 20:
                    # Non-HTML content line
                    description_lines.append(line)
                
                if len(description_lines) >= 3:  # Limit description length
                    break
            
            description = ' '.join(description_lines) if description_lines else f"Exploit for {cve_id} in category {category}"
            
            # Get file metadata
            file_stats = os.stat(file_path)
            modified_time = datetime.fromtimestamp(file_stats.st_mtime)
            
            # Determine exploit type and severity
            exploit_type = category.lower()
            severity = self._determine_severity(exploit_type, content)
            
            # Extract additional metadata from content
            references = self._extract_references(content)
            
            # Create standardized vulnerability
            vulnerability = Vulnerability(
                id=Vulnerability.create_id(exploit_url),
                content_hash=Vulnerability.create_content_hash(content),
                path_url=exploit_url,
                source=self.name,
                source_id=f"{relative_path}#{cve_id}",
                content=content,
                type=VulnerabilityType.EXPLOIT,
                cve_id=cve_id,
                title=title,
                description=description,
                severity=severity,
                published_at=modified_time.isoformat(),
                updated_at=modified_time.isoformat(),
                reference_urls=references,
                tags={self.name, "exploit", exploit_type, category},
                exploit_type=exploit_type,
                exploit_file_path=relative_path
            )
            
            return vulnerability.to_dict()
            
        except Exception as e:
            logger.error(f"Error processing exploit {file_path}: {e}")
            return None
    
    def _determine_severity(self, exploit_type: str, content: str) -> str:
        """Determine exploit severity based on type and content."""
        # Remote code execution exploits are typically critical
        if 'remote' in exploit_type or 'rce' in content.lower():
            return "CRITICAL"
        
        # Buffer overflow, privilege escalation typically high
        if any(keyword in content.lower() for keyword in ['buffer overflow', 'privilege escalation', 'root', 'admin']):
            return "HIGH"
        
        # DoS attacks typically medium
        if 'dos' in exploit_type or 'denial of service' in content.lower():
            return "MEDIUM"
        
        # Default for exploits
        return "HIGH"
    
    def _extract_references(self, content: str) -> set:
        """Extract reference URLs from exploit content."""
        references = set()
        
        # Look for URLs in content
        url_pattern = re.compile(r'https?://[^\s<>"]+', re.IGNORECASE)
        urls = url_pattern.findall(content)
        
        for url in urls:
            # Clean up URL (remove trailing punctuation)
            clean_url = url.rstrip('.,;:!?)')
            if len(clean_url) > 10:  # Skip very short URLs
                references.add(clean_url)
        
        return references 